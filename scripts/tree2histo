#!/usr/bin/env python
"""
Read a list of ROOT files and produce histograms
"""
from __future__ import print_function
from __future__ import division

import ROOT
from root_numpy import tree2array, fill_hist
import numpy as np

import multiprocessing as mp
import glob

n_workers = 1
def read_partial_events(
    file_name, tree_name, branches, selections, start, stop):

    chain = ROOT.TChain(tree_name, tree_name)
    chain.Add(file_name)
    nentries = chain.GetEntries()

    event_info = tree2array(chain,
                            branches=branches,
                            selection=selections,
                            start=start,
                            stop=stop)
    return event_info

def read_events(chain, branches, selections, start, stop):
    event_info = tree2array(chain,
                            branches=branches,
                            selection=selections,
                            start=start,
                            stop=stop)
    return event_info

def read_file(file_name, tree_name, branches, selections):
    chain = ROOT.TChain(tree_name, tree_name)
    chain.Add(file_name)
    nentries = chain.GetEntries()
    print("{} contains {:,} events".format(file_name, nentries))

    if n_workers > 1 and nentries > 2000000:
        # split the jobs
        # using multiple workers does not help
        # when each worker processes < ~2M events
        even = nentries//n_workers
        event_info_list = []

        pool = mp.Pool(processes=n_workers)
        ithread = 0
        threads = []
        while ithread < n_workers-1:
            start = even*ithread
            stop = even*(1+ithread)
            print("start {} and stop {}".format(start, stop))
            x = pool.apply_async(read_partial_events,
                                 args=(file_name, tree_name,
                                       branches, selections,
                                       start, stop))
            threads.append(x)
            ithread += 1
        # another thread to do the rest
        print("start {} to the end".format(start))
        x = pool.apply_async(read_partial_events,
                             args=(file_name, tree_name,
                                   branches, selections,
                                   start, None))
        threads.append(x)

        event_info = np.concatenate([x.get() for x in threads])
    else:
        event_info = read_events(chain,
                                 branches, selections,
                                 None, None)

    return event_info


def make_hists(event_info, hist_opts, outname, weight_name=None):
    outfile = ROOT.TFile.Open(outname, 'recreate')
    histograms = []

    for hist_opt in hist_opts:
        #print(hist_opt)
        if(len(hist_opt) < 5):
            print(hist_opt, "not enough info")
            continue

        h_type, h_name, h_low, h_high, h_nbins = hist_opt[:5]
        if len(hist_opt) > 5:
            h_xlabel, h_ylabel = hist_opt[5:7]
        else:
            h_xlabel, h_ylabel = None, None

        if 'TH1' in h_type:
            h1 = getattr(ROOT, h_type)(h_name, h_name, h_nbins, h_low, h_high)
            if h_xlabel:
                h1.SetXTitle(h_xlabel)
                h1.SetYTitle(h_ylabel)
        else:
            print("Not implemented")
            continue

        if weight_name:
            fill_hist(h1, event_info[h_name], weights=event_info[weight_name])
        else:
            fill_hist(h1, event_info[h_name])

        histograms.append(h1)

    for hist in histograms:
        hist.Write()

    outfile.Close()

if __name__ == "__main__":
    import argparse
    import os
    import yaml

    parser = argparse.ArgumentParser(description='Compare two Hmumu Ntuples')
    add_arg = parser.add_argument
    add_arg('config', type=str, help='config file')
    add_arg('-w', '--workers', type=int, help='number of workers', default=1)

    args = parser.parse_args()
    n_workers = args.workers
    print("Workers empolyed: {}".format(n_workers))

    with open(args.config) as f:
        if hasattr(yaml, "FullLoader"):
            config = yaml.load(f, Loader=yaml.FullLoader)
        else:
            config = yaml.load(f)

    branches = config['branches']
    files = config['files']
    outnames = config['outnames']
    tree_name = config['tree_name']
    weight_name = config['weight_name']
    selections = config['selections']
    hist_opts = config['hists']

    for ise,selection in enumerate(selections):
    ## process each file
        for file_name, outname in zip(files, outnames):
            print("Processing: {}".format(file_name))
            event_info = read_file(file_name, tree_name, branches, selection)
            make_hists(event_info, hist_opts, outname, weight_name=weight_name)
