#!/usr/bin/env python
from __future__ import print_function

import argparse
import pickle
import sys
import os
import multiprocessing as mp
import threading
import time

import xgboost as xgb
import ROOT

import numpy as np
import numpy.lib.recfunctions as rfn
from root_numpy import tree2array, array2root

debug_tag = ' \x1b[33m[Post Processing] [Debug]\x1b[0m '
def get_model_from(input_file):
    model = xgb.Booster()
    model.load_model(input_file)
    return model

def get_transformer_from(input_file):
    transformer = pickle.load(open(input_file, 'rb'))
    return transformer

def read_partial_events(file_name, tree_name, branches,
                        selections, start, stop,
                        models, transformers
                       ):
    print("PID {} runs events from {} to {}".format(
        os.getpid(), start, stop))
    t_start = time.time()
    chain = ROOT.TChain(tree_name, tree_name)
    chain.AddFile(file_name)
    nentries = chain.GetEntries()

    event_info = tree2array(chain,
                           branches=branches,
                           selection=selections,
                           start=start,
                           stop=stop)
    t_read = time.time()
    res = get_BDT_score(event_info, models, transformers)
    t_res = time.time()
    print("Thread: {} spends {:.0f} seconds in reading and {:.0f} seconds "
          "in calculating BDT".format(os.getpid(), t_read-t_start, t_res - t_read))
    return res


def get_BDT_score(all_events, models, transformers):
    tot_scores = np.full(all_events.shape, -1.,
                        dtype=[
                            ('ClassOut_XGB_fJVT_Higgs', np.float32),
                            ('ClassOut_XGB_fJVT_VBF', np.float32),
                            ('Event_XGB_fJVT_Category', np.float32)
                        ])

    for jet_idx in range(3):

        if jet_idx < 2:
            mask = all_events['Jets_jetMultip'] == jet_idx
        else:
            mask = all_events['Jets_jetMultip'] >= jet_idx

        n_events = all_events['Jets_jetMultip'][mask].shape[0]

        const_ary = np.full((n_events, 1), -9999)
        # higgs-BDT, VBF-BDT and Event-Category
        output_info = np.full((n_events, 3), -9999., dtype=np.float32)

        # prepare the Matrix
        if jet_idx == 2:
            input_array = np.concatenate(
                [all_events[bb][mask].reshape(n_events, -1) for bb in branches[:11]] + [const_ary] \
                + [all_events[bb][mask].reshape(n_events, -1) for bb in branches[11:17]] + \
                [const_ary, np.abs(all_events[branches[17]][mask].reshape(n_events, -1))],
                axis=1)
        else:
            input_array = np.concatenate(
                [all_events[bb][mask].reshape(n_events, -1) for bb in branches[:10]] \
                + [const_ary, const_ary] \
                + [all_events[bb][mask].reshape(n_events, -1) for bb in branches[11:17]] + \
                [const_ary, np.abs(all_events[branches[17]][mask].reshape(n_events, -1))],
                axis=1)
        # print("MY Input shape:", input_array.shape)
        #print(input_array[:3, :])
        input_matrix = xgb.DMatrix(input_array)

        # each BDT have 4 different versions
        # evaluate all events for the four different models
        all_scores = []
        vbf_scores = []
        for im in range(4):
            bdt_model = models[jet_idx][im]
            score_trans = transformers[jet_idx][im]
            score = bdt_model.predict(input_matrix)
            trans_score = score_trans.transform(score.reshape(-1,1)).reshape(-1)
            all_scores.append(trans_score)
            if jet_idx == 2: ## DO VBF BDT
                icat = 'VBF'
                bdt_model = models[icat][im]
                score_trans = transformers[icat][im]
                score = bdt_model.predict(input_matrix)
                trans_score = score_trans.transform(score.reshape(-1,1)).reshape(-1)
                vbf_scores.append(trans_score)

        #print(all_scores[0][0::4].shape)
        #print(output_info[0::4, 0].shape)
        # Now assign Higgs BDT values
        output_info[0::4, 0] = 1 - all_scores[0][0::4]
        output_info[1::4, 0] = 1 - all_scores[1][1::4]
        output_info[2::4, 0] = 1 - all_scores[2][2::4]
        output_info[3::4, 0] = 1 - all_scores[3][3::4]
        #print(all_scores[0][:3])
        #print(all_scores[1][:3])
        #print(all_scores[2][:3])
        #print(all_scores[3][:3])

        if jet_idx == 2:
            output_info[0::4, 1] = 1 - vbf_scores[0][0::4]
            output_info[1::4, 1] = 1 - vbf_scores[1][1::4]
            output_info[2::4, 1] = 1 - vbf_scores[2][2::4]
            output_info[3::4, 1] = 1 - vbf_scores[3][3::4]

        ## Now figure out the category
        higgs = output_info[:, 0]
        vbf = output_info [:, 1]
        if jet_idx == 2:
            output_info[ vbf >= 0.89, 2] = 1
            output_info[(vbf < 0.89)&(vbf >= 0.77), 2] = 2
            output_info[(vbf < 0.77)&(vbf >= 0.60), 2] = 3
            output_info[(vbf < 0.60)&(vbf >= 0.48), 2] = 4
            output_info[(vbf < 0.48)&(vbf >= 0.22), 2] = 5
            output_info[vbf < 0.22, 2] = 6
        elif jet_idx == 1:
            output_info[ higgs >= 0.78, 2] = 7
            output_info[(higgs < 0.78)&(higgs >= 0.38), 2] = 8
            output_info[higgs < 0.38, 2] = 9
        else:
            output_info[ higgs >= 0.75, 2] = 10
            output_info[(higgs < 0.75)&(higgs >= 0.35), 2] = 11
            output_info[higgs < 0.35, 2] = 12


        tot_scores['ClassOut_XGB_fJVT_Higgs'][mask] = output_info[:, 0]
        tot_scores['ClassOut_XGB_fJVT_VBF'][mask] = output_info[:, 1]
        tot_scores['Event_XGB_fJVT_Category'][mask] = output_info[:, 2]
        print(tot_scores['Event_XGB_fJVT_Category'][mask][:10])

    # write only the BDT branches
    return tot_scores




if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('input', help='input file')
    parser.add_argument('output', help='output file')
    parser.add_argument('-t', '--tree', help='tree_name', default='DiMuonNtuple')
    parser.add_argument('-w', '--workers', help='number of workers', type=int, default=1)
    parser.add_argument('-m', '--modeldir', help='model directory', type=str, default='.')
    parser.add_argument('-b', '--batch_size', help='process the data in batches',
                        type=int, default=-1)
    args = parser.parse_args()

    file_name = args.input
    tree_name = args.tree
    n_workers = args.workers
    output = args.output
    batch_size = args.batch_size
    model_base_dir = args.modeldir
    if os.path.exists(output):
        print("Removed existing BDT output: {}".format(output))
        os.remove(output)

    for k, v in args._get_kwargs():
        print('  {:20}:  {}'.format(k, v))

    models = {}
    transformers = {}

    catlabel = ['zero_jet', 'one_jet', 'two_jet']
    ## 0, 1 and 2 jets --- jet-category
    # each jet category have 4 models??
    for cat in range(len(catlabel)):
        model_dir = os.path.join(model_base_dir, 'models', 'conf', 'fjvt', '{}_{}.{}')

        models[cat] = {
            model_index: get_model_from(model_dir.format(catlabel[cat], model_index, 'h5')) for model_index in range(4)
        }
        transformers[cat] = { model_index: get_transformer_from(model_dir.format("score_transformer_"+catlabel[cat], model_index, 'pkl'))
                             for model_index in range(4)}

        if cat == 2:
            models['VBF'] = { model_index: get_model_from(model_dir.format('VBF_two_jet', model_index, 'h5'))
                             for model_index in range(4)}
            transformers['VBF'] = { model_index: get_transformer_from(model_dir.format('score_transformer_two_jet_VBF', model_index, 'pkl')) 
                                   for model_index in range(4)}

    print('{} -- Printing available (standard) models (dictionary):'.format(debug_tag))
    for cat in models:
        print(' ', cat)
        for index, model in models[cat].iteritems():
            print('   ', index, ': ', str(model))
        for index, transformer in transformers[cat].iteritems():
            print('   ', index, ': ', str(transformer))

    print('{} -- Looking at {} tree'.format(debug_tag, tree_name))

    in_file = ROOT.TFile.Open(file_name)
    in_tree = in_file.Get(tree_name)

    neventTotal = in_tree.GetEntries()
    print('Tree has {:,} entries'.format(neventTotal))
    if batch_size < 0 and neventTotal > 100000000:
        print("number of events larger than 100 M, process in batches")
        batch_size = 100000000
    else:
        batch_size = neventTotal

    branches = [
        'Jets_PT_Lead', 'Jets_Eta_Lead', 'Dphi_JZ_Lead', 'Jets_Phi_Lead', 'Jets_E_Lead',
        'Jets_PT_Sub', 'Jets_Eta_Sub', 'Dphi_JZ_Sub', 'Jets_Phi_Sub', 'Jets_E_Sub',
        'Event_MET',
        'DiJet_PT', "DiJet_Rapidity", "DiJet_Dphi", "DiJet_Minv",
        "Z_PT", "Z_Rapidity", "Muons_CosThetaStar", "Jets_jetMultip",
        'weight',
    ]

    t_start = time.time()
    # read in all events, use multi-threads only if events > 10 M
    # multi-threads here seem provide no help...
    if n_workers > 1 and neventTotal > 10000000:
        even = neventTotal//n_workers
        event_info_list = []
        print("{} workers, each work on {} events".format(n_workers, even))

        pool = mp.Pool(processes=n_workers)
        ithread = 0
        threads = []
        while ithread < n_workers-1:
            start = even*ithread
            stop = even*(1+ithread)
            print("start {} and stop {}".format(start, stop))
            x = pool.apply_async(read_partial_events,
                                 args=(file_name, tree_name,
                                       branches, None,
                                       start, stop,
                                       models, transformers
                                      ))
            threads.append(x.get())
            ithread += 1

        print("Last one run {} Evens from {} to the end".format(neventTotal-stop, stop))
        x = pool.apply_async(read_partial_events,
                             args=(file_name, tree_name,
                                   branches, None,
                                   stop, None, models, transformers))
        threads.append(x.get())

        #all_scores = np.concatenate([x.get() for x in threads])
        all_scores = np.concatenate(threads)
        array2root(all_scores, output, tree_name, 'recreate')

        exit(0)

    else:
        all_events = tree2array(
            in_tree,
            branches=branches,
            selection=None,
            start=None,
            stop=None,
            step=None)

    t_read = time.time()
    print("Takes {:.1f} seconds to read in {:,} events".format(t_read - t_start,
                                                             all_events.shape[0]))

    t_bdt = t_read
    nbatches = neventTotal//batch_size
    print("process in {} batches".format(nbatches))

    for ibatch in range(nbatches):
        start = ibatch * batch_size
        end = (ibatch+1) * batch_size
        particle_events = all_events[start:end]
        p_score = get_BDT_score(particle_events, models, transformers)
        array2root(p_score, output, tree_name, 'update')
        t_now = time.time()
        print("Takes {:.1f} seconds to finish a batch".format(t_now - t_bdt))
        t_bdt = t_now

    if end < neventTotal:
        print("processed: {} events, now deal with the rest".format(end))
        p_score = get_BDT_score(all_events[end:], models, transformers, output)
        array2root(p_score, output, tree_name, 'update')
